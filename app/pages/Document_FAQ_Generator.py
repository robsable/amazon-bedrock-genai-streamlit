import streamlit as st
from st_pages import add_indentation
from datetime import datetime, timezone, timedelta

from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader

from pages.lib import models_shared

def get_docs(doc_selection):
    
    loader = PyPDFLoader(file_path=doc_selection)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", " "], chunk_size=10000, chunk_overlap=0 
    )
    docs = text_splitter.split_documents(documents=documents)
    
    return docs


def get_summary(model_id=None, temperature=0.0, return_intermediate_steps=False, doc_selection=None):
    
    map_prompt_template = "{text}\n\nWrite an expected list of frequently asked questions and their answers based on the above content. List each question on a new line beginning with Q:. Then leave a blank line. On a new line below that, list each answer beginning with A: "
    map_prompt = PromptTemplate(template=map_prompt_template, input_variables=["text"])
    
    llm, is_chat = models_shared.get_llm(model_id, temperature)
    docs = get_docs(doc_selection=doc_selection)
    
    chain = load_summarize_chain(llm, chain_type="map_reduce", map_prompt=map_prompt, return_intermediate_steps=return_intermediate_steps)
    
    if return_intermediate_steps:
        return chain.invoke({"input_documents": docs}, return_only_outputs=True)
    else:
        return chain.invoke(docs, return_only_outputs=True)

#################
# Streamlit App #
#################
st.set_page_config(layout="wide", page_title="Document Summary & FAQs", page_icon=":interrobang:")
st.title("Document Summary & FAQs")
st.caption("**Instructions:**  (1) Select a document  (2) Select a model (3) Click Generate")
add_indentation()

# Get Bedrock LLM Models options
model_options = list(models_shared.model_options_dict)

timezone_offset = -4.0  # Eastern Standard Time (UTCâˆ’08:00)
tzinfo = timezone(timedelta(hours=timezone_offset))

col1, col2 = st.columns([.35,.65])

pdf_options_dict = {
    "./static/beginners-guide.pdf" : "AWS Beginners Guide",
    "./static/awsgsg-intro.pdf" : "AWS Intro",
}
pdf_options = list(pdf_options_dict)

with col1:
    doc_selection = st.radio("**Select a document:**", pdf_options, format_func=pdf_options_dict.get, horizontal=True)
    return_intermediate_steps = st.checkbox("Generate FAQs", value=True)
    summarize_button = st.button("Generate", type="primary")

with col2:
    selected_model = st.radio("**Select a model:**", 
        model_options,
        format_func=models_shared.get_model_label,
        horizontal=True
    )

if summarize_button:
    st.subheader("Document summary")
    st.write("**GENERATED BY:** "+selected_model)

    start = datetime.now(tzinfo)

    with st.spinner("Running..."):
        response_content = get_summary(model_id=selected_model, temperature=0.0, return_intermediate_steps=return_intermediate_steps, doc_selection=doc_selection)

    end = datetime.now(tzinfo)
    st.write("**TIME ELAPSED** = " + str(end - start))

    if return_intermediate_steps:

        st.write(response_content["output_text"])

        st.subheader("Section FAQs")

        for step in response_content["intermediate_steps"]:
            st.write(step)
            st.markdown("---")

    else:
        st.write(response_content["output_text"])

